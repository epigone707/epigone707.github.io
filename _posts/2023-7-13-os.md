---
layout: post
title: "Operating System Interview Note"
description: "Operating System Interview Note"
category: tech 
tags: interview os
modify: 2023-07-13 18:09:00
---

# Contents
* TOC
{:toc}

# 3 Process
## 3.1 Process Concept
A process is basically a program in execution. To put it in simple terms, we write our computer programs in a text file and when we execute this program, it becomes a process which performs all the tasks mentioned in the program.

When a program is loaded into the memory and it becomes a process, it can be divided into four sections: stack, heap, text and data.
- Stack: the temporary data such as method/function parameters, return address and local variables.
- Heap: dynamically allocated memory to a process during its run time.
- Text: the compiled program code, read in from non-volatile storage when the program is launched.
- Data: global and static variables, allocated and initialized prior to executing main.
  
![image](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter3/3_01_Process_Memory.jpg)

### Process State
Processes may be in one of 5 states:
- New - The process is in the stage of being created.
- Ready - The process has all the resources available that it needs to run, but the CPU is not currently working on this process's instructions.
- Running - The CPU is working on this process's instructions.
- Waiting - The process cannot run at the moment, because it is waiting for some resource to become available or for some event to occur. For example the process may be waiting for keyboard input, disk access request, inter-process messages, a timer to go off, or a child process to finish.
- Terminated - The process has completed.

![image](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter3/3_02_ProcessState.jpg)

### Process Control Block (PCB)
For each process there is a Process Control Block, which stores the following process-specific information:
- Process State - Running, waiting, etc.
- Process ID, and parent process ID.
- CPU registers - register set where process needs to be stored for execution for running state
- Program Counter (PC) - a pointer to the address of the next instruction to be executed for this process
- CPU Scheduling information - Such as priority information and pointers to scheduling queues.
- Memory Management information - page/segment table and memory limits
- Accounting information - user and kernel CPU time consumed, account numbers, limits, etc.
- I/O Status information - list of I/O devices allocated to the process.

![image](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter3/3_04_ProcessSwitch.jpg)

more: https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html

## 3.2 Process Scheduling
The two main objectives of the process scheduling system are to keep the CPU busy at all times and to deliver "acceptable" response times for all programs.

- All processes are stored in the **job queue**.
- Processes in the Ready state are placed in the **ready queue**.
- Processes waiting for a device to become available or to deliver data are placed in **device queues**. There is generally a separate device queue for each device.
- Other queues may also be created and used as needed.

### Context Switch
a context switch is the process of storing the state of a process or thread, so that it can be restored and resume execution at a later point, and then restoring a different, previously saved, state.

WHEN?

Most commonly, one process must be switched out of the CPU so another process can run. This context switch can be triggered by the process making itself unrunnable, such as by waiting for an I/O or synchronization operation to complete. 

On a pre-emptive multitasking system, the scheduler may also switch out processes that are still runnable. To prevent other processes from being starved of CPU time, pre-emptive schedulers often configure a timer interrupt to fire when a process exceeds its time slice. This interrupt ensures that the scheduler will gain control to perform a context switch.

Context switching happens VERY frequently

HOW?

In the Linux kernel, context switching involves loading the corresponding process control block (PCB) stored in the PCB table in the kernel stack to retrieve information about the state of the new process. CPU state information including the registers, stack pointer, and program counter as well as memory management information like segmentation tables and page tables (unless the old process shares the memory with the new) are loaded from the PCB for the new process.

## 3.3 Operations on Processes
see section 3.3 in https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/3_Processes.html

## 3.4 Inter Process Communication (IPC)
![image](https://www.cs.uic.edu/~jbell/CourseNotes/OperatingSystems/images/Chapter3/3_12_CommunicationsModels.jpg)

*Communications models: (a) Message passing. (b) Shared memory.*

### Shared Memory
- Multiple processes are given access to the same block of memory, which creates a shared buffer for the processes to communicate with each other.
- Shared memory is generally preferable when large amounts of information must be shared quickly on the same computer.

### Message Passing
- Message passing systems must support at a minimum system calls for "send message" and "receive message".
- Either the sending or receiving of messages ( or neither or both ) may be either blocking or non-blocking.
- Messages are passed via queues
- Message Passing requires system calls for every message transfer, and is therefore slower, but it is simpler to set up and works well across multiple computers. Message passing is generally preferable when the amount and/or frequency of data transfers is small, or when multiple computers are involved.

## 3.6 Communication in Client-Server Systems

### Sockets
- A socket is an endpoint for communication.
- Two processes communicating over a network often use a pair of connected sockets as a communication channel. Software that is designed for client-server operation may also use sockets for communication between two processes running on the same computer - For example the UI for a database program may communicate with the back-end database manager using sockets. ( If the program were developed this way from the beginning, it makes it very easy to port it from a single-computer system to a networked application. )
- A socket is identified by an IP address concatenated with a port number

Communication channels via sockets may be of one of two major forms:
- Connection-oriented ( TCP, Transmission Control Protocol ) connections emulate a telephone connection. All packets sent down the connection are guaranteed to arrive in good condition at the other end, and to be delivered to the receiving process in the order in which they were sent. The TCP layer of the network protocol takes steps to verify all packets sent, re-send packets if necessary, and arrange the received packets in the proper order before delivering them to the receiving process. There is a certain amount of overhead involved in this procedure, and if one packet is missing or delayed, then any packets which follow will have to wait until the errant packet is delivered before they can continue their journey.
- Connectionless ( UDP, User Datagram Protocol ) emulate individual telegrams. There is no guarantee that any particular packet will get through undamaged, and no guarantee that the packets will get delivered in any particular order. There may even be duplicate packets delivered, depending on how the intermediary connections are configured. UDP transmissions are much faster than TCP, but applications must implement their own error checking and recovery procedures.


Sockets are considered a low-level communications channel, and processes may often choose to use something at a higher level, such as those covered in the next two sections.


### Remote Procedure Calls (RPC)
The general concept of RPC is to make procedure calls similarly to calling on ordinary local procedures, except the procedure being called lies on a remote machine.

Implementation involves stubs on either end of the connection.
- The local process calls on the stub, much as it would call upon a local procedure.
- The RPC system packages up ( marshals ) the parameters to the procedure call, and transmits them to the remote system.
- On the remote side, the RPC daemon accepts the parameters and calls upon the appropriate remote procedure to perform the requested work.
- Any results to be returned are then packaged up and sent back by the RPC system to the local system, which then unpackages them and returns the results to the local calling procedure.

### Pipes
Pipes are one of the earliest and simplest channels of communications between ( UNIX ) processes.

# Threads




# Main-Memory Management

## Bélády's anomaly

Bélády's anomaly is the phenomenon in which increasing the number of page frames results in an increase in the number of page faults for certain memory access patterns. This phenomenon is commonly experienced when using the first-in first-out (FIFO) page replacement algorithm.

In FIFO, the page fault may or may not increase as the page frames increase, but in optimal and stack-based algorithms like LRU, as the page frames increase, the page fault decreases.

Example:

```
time ->
Page requests	3	2	1	0	3	2	4	3	2	1	0	4
Newest page	   [3] [2] [1] [0] [3] [2] [4]	4	4  [1] [0]	0
 	 	            3	2	1	0	3   2	2	2	4	1	1
Oldest page	 	 	    3	2	1	0	3	3	3	2	4 	4
```

Using three page frames, nine page faults occur.

```
time->
Page requests	3	2	1	0	3	2	4	3	2	1	0	4
Newest page    [3] [2] [1] [0]	0	0  [4] [3] [2] [1] [0] [4]
 	 	            3	2	1	1	1	0	4	3	2	1	0
 	 	 	            3	2	2	2	1	0	4	3	2	1
Oldest page	 	 	 	    3	3	3	2	1	0	4	3	2
```

Increasing to four page frames causes ten page faults to occur. Page faults are in `[]`.

# Scheduling

## What is Deadlock and what are its four necessary conditions?

https://afteracademy.com/blog/what-is-deadlock-and-what-are-its-four-necessary-conditions/

Deadlock is a situation where a set of processes are blocked as each process is holding resources and waits to acquire resources held by another process. This leads to infinite waiting.

Necessary Conditions of Deadlock:

- Mutual Exclusion: A resource can be held by only one process at a time
- Hold and Wait: A process can hold a number of resources at a time and at the same time, it can request for other resources that are being held by some other process.
- No preemption: A resource can't be preempted from the process by another process, forcefully. For example, if a process P1 is using some resource R, then some other process P2 can't forcefully take that resource.
- Circular Wait: Circular wait is a condition when the first process is waiting for the resource held by the second process, the second process is waiting for the resource held by the third process, and so on. At last, the last process is waiting for the resource held by the first process.

Deadlock will happen if all the above four conditions happen simultaneously.

## Semaphore

Semaphore is a synchronization mechanism that is used to control access to shared resources in multi-threaded or multi-process systems. It maintains a count of available resources and provides two atomic operations: wait() and signal(). The counter allows it to control access to a finite pool of resources.

```c++
wait(S) {
   while (S<=0);
   S--;
}

signal(S) {
   S++;
}
```

# Other

## Spooling

Spooling (Simultaneous Peripheral Operations Online) is an I/O management or buffer management technique that allows the data of the input/output processes to be temporarily stored in the secondary memory (Hard Drive, SSD, etc.) which will be executed by the CPU or a device or a program. These data will be stored in the secondary memory until the system or a program requests the data for its execution.
